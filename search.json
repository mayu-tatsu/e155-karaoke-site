[
  {
    "objectID": "project_proposal.html",
    "href": "project_proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "This project seeks to emulate a karaoke machine by allowing a user to select from a set list of songs and displaying appropriately-timed lyrics accordingly. Once the song has finished, the project will grade the user’s performance — with both a numeric score and letter grade — based on how on-pitch they are.\nTo be more specific, this will be done by sampling the user’s singing with the FPGA and a MEMS PDM microphone, during which the former will perform decimation (see New FPGA Functionality) on the digital output of the mic, bringing the sample rate down to 16 kHz. Then, the FPGA will send this processed information to the MCU via SPI communication, so that it can further process such with FFT computations. It will also handle the storage of expected and detected notes throughout each song. Finally, the MCU will communicate with an LCD over I2C to display the corresponding lyrics of whatever song the user has chosen to sing and display the final score of the user’s performance."
  },
  {
    "objectID": "project_proposal.html#project-overview",
    "href": "project_proposal.html#project-overview",
    "title": "Project Proposal",
    "section": "",
    "text": "This project seeks to emulate a karaoke machine by allowing a user to select from a set list of songs and displaying appropriately-timed lyrics accordingly. Once the song has finished, the project will grade the user’s performance — with both a numeric score and letter grade — based on how on-pitch they are.\nTo be more specific, this will be done by sampling the user’s singing with the FPGA and a MEMS PDM microphone, during which the former will perform decimation (see New FPGA Functionality) on the digital output of the mic, bringing the sample rate down to 16 kHz. Then, the FPGA will send this processed information to the MCU via SPI communication, so that it can further process such with FFT computations. It will also handle the storage of expected and detected notes throughout each song. Finally, the MCU will communicate with an LCD over I2C to display the corresponding lyrics of whatever song the user has chosen to sing and display the final score of the user’s performance."
  },
  {
    "objectID": "project_proposal.html#specifications",
    "href": "project_proposal.html#specifications",
    "title": "Project Proposal",
    "section": "Specifications",
    "text": "Specifications\n\nDesign allows the user to choose a song through external hardware\nDesign detects input frequencies between 300 to 2000 Hz\nDesign scores the user’s singing by comparing detected and expected notes\nDesign plays back the expected song through a speaker as reference\nDesign utilizes a pitch and delay media format (as seen in Fur Elise, Lab 4)\nDisplays properly-timed lyrics on an LCD screen\nLCD display does not flicker"
  },
  {
    "objectID": "project_proposal.html#project-management",
    "href": "project_proposal.html#project-management",
    "title": "Project Proposal",
    "section": "Project Management",
    "text": "Project Management\n\nBill of Materials\n\n\n\n\n\n\nPart Name\nPart Number\nQuantity\nPrice\nVendor\n\n\n\n\nAdafruit PDM MEMS Microphone Breakout\nMP34DT01-M\n1\n$11.23 ($4.95 part, $6.28 shipping + tax)\nAdafruit\n\n\nHosyond I2C 2004 LCD Module\nHD44780U\n1\n$26.32 ($16.99 part, $6.99 shipping, $2.34 estimated tax)\nAmazon\n\n\nCapacitor\n100nF Ceramic Capacitor\n1\n$0\nStockroom\n\n\nTOTAL\n\n\n$37.55\n\n\n\n\n\n\nTable 1: Bill of materials\n\n\n\nNote that if the team discovers that they need any additional, basic resources (such as resistors, capacitors, etc.) later on in the project, these will be taken from either the Engineering Stockroom or Digital Lab at no cost.\n\n\nTimeline\n\n\n\n\n\n\n\n\n\n\n\n\nTask(s)\nDate\n\n\n\n\nProject proposal\nFinish project proposal\n10/16/25\n\n\n\nStart project\n10/30/25\n\n\n\nStudy PDM to PCM decimation\n11/6/25\n\n\n\nImplement new decimation FPGA functionality\n11/7/25\n\n\n\nDetect all input notes accurately with microphone\n11/16/25\n\n\nMidpoint report and demo\nFinish midpoint report and prepare demo\n11/20/25\n\n\n\nSynchronize LCD output notes/lyrics with song(s)\n11/27/25\n\n\n\nPolish off project’s final appearance\n12/3/25\n\n\nFinal checkoff\nFinish project completely\n12/5/25\n\n\nFinal report\nFinish final report\n12/7/25\n\n\nDemo day\n\n12/8/25\n\n\n\n\n\nTable 2: Rough timeline with key dates\n\n\n\n\n\nTask Delegation\n\n\n\n\n\n\n\n\n\n\nMayu\nQuinn\n\n\n\n\n\nStudy PDM to PCM decimation\n\n\nStudy PDM to PCM decimation\n\n\n\n\nStart FPGA code\n\n\nStart LCD code\nTranscribe song(s)\n\n\n\n\nCheck LCD code\n\n\nCheck FPGA code\n\n\n\n\nStudy FFT calculations and libraries\n\n\nStudy FFT calculations and libraries\n\n\n\n\nDecide on interrupts and timers for MCU\n\n\nDecide on interrupts and timers for MCU\n\n\n\n\nAssemble circuit\n\n\nCheck circuit\n\n\n\n\nWrite verification\n\n\nWrite verification\n\n\n\n\nWrite Documentation\n\n\nWrite Documentation\n\n\n\n\n\n\nTable 3: Task delegation\n\n\n\nOverall, the team hopes to complete the vast majority of the project’s tasks together, so as to receive an equal and holistic learning experience."
  },
  {
    "objectID": "project_proposal.html#design-details",
    "href": "project_proposal.html#design-details",
    "title": "Project Proposal",
    "section": "Design Details",
    "text": "Design Details\n\nNew MCU Functionality\nThe new MCU functionality intended to be used is the DMA peripheral to onload buffered data for the PCM data coming in from the FPGA through SPI protocol.\n\n\nNew FPGA Functionality\nThe new FPGA functionality intended to be used is decimation. In short, decimation is a term in (digital) signal processing that describes the removal of samples so as to reduce the complexity of subsequent computations.\n\n\nNew Non-Trivial Hardware\nThe two new, non-trivial pieces of hardware that will be used in this project are the Hoysond LCD module and the Adafruit PDM microphone.\n\n\nRiskiest Element\nThe riskiest element of the project will be the microphone. We are not sure how accurate it will be able to process sounds and output a solid PDM. It is also important to note that we will be demoing the design during a noisy lab room, so we are expecting difficulty in isolating the singing. We will attempt to mitigate the risks by implementing a sigma-delta modulator that we can control via switch."
  },
  {
    "objectID": "project_proposal.html#technical-documentation",
    "href": "project_proposal.html#technical-documentation",
    "title": "Project Proposal",
    "section": "Technical Documentation",
    "text": "Technical Documentation\n\nBlock Diagram\n\n\n\n\n\n\nFigure 1: Block diagram\n\n\n\nThe block diagram depicted in Figure 1 provides a general outline of all protocols and interfaces that the project will comprise.\n\n\nCalculations of Critical Parameters\n\nPDM to PCM Decimation Parameters (Filter Design)\nPage four of the MP34DT01-M datasheet gives the following values:\nClock (@ \\(Vdd=1.8V\\), \\(T=25\\degree C\\)) = 2.4 MHz (Min. 1 MHz, Max. 3.25 MHz)\nAOP (Acoustic Overload Point) = 120 dBSPL\nSNR (Signal-to-Noise Ratio) = 61 dB\nDynamic Range = SNR + (AOP - 94 dbSPL) = 61 dB + (120 dbSPL - 94 dbSPL) = 87 bB\n- Assuming that there is ~6 dB per bit (realistically 6.2 per bit but rounding down), the design will need a PCM word size of at least 15 bits to cover the full dynamic range of the microphone. (\\(87/6=14.5\\), round up to 15 bits)\nThus, the values the team decided on are:\nOutput Sample Rate: 16 kHz → Bandwidth / Nyquist: 8 kHz\n- Most fundamental frequencies and harmonics of human singing fall below 8 kHz, and setting the Nyquist value at 16 kHz comfortably covers this band. - This has a lower processing and memory cost compared to standard 48 kHz audio.\n- FFT frequency bins and time resolution are balanced at this sample rate for pitch detection and scoring (see below!).\nPDM Sample Rate: 2.304 MHz\n- Based on clock range: 1 - 3.25 MHz\n- Power of 2: Important for decimation ratio –&gt; Multi-stage decimation.\nDecimation Ratio: \\(2304 kHz / 16 kHz = 144\\)\n\n\n\n\n\n\nFigure 2: Frequency response diagram\n\n\n\nObserving the diagram provided in Figure 2 above, after 6 kHz, the frequency response starts becoming a lot more sensitive. It’s a pass until then, and then the transition band starts from there. Beyond 10 kHz, the frequency response data isn’t displayed, so assuming the worst case scenario, the stop band should start from there.\nPass-band: 0 - 6 kHz\nStop Band: 10 kHz\nSNR of Output Signal: 80 dB\n- Humans can’t detect signals beyond 70 dB. - Allowing for increased SNR deterioration (of around 7 dB from 87 dB), the team can balance out the computational usage to quality required for a karaoke machine.\nMax. Ripple: +/- 1 dB\n- Individual filters will need to have tighter specs than this overall maximum 1 dB ripple, so for less load, it’s relaxed compared to the high quality audio standard of 0.1 dB.\nStop Band Attenuation = 60 dB\n- Worst-case assumption: PDM noise above 8 kHz (Nyquist) = −40 dB per 16 kHz band\n# all Hz\nfPDM      = 2.304e6\nfPDM/2    = 1.152e6\nfs        = 16e3\nfs/2      = 8e3\n\nN_bands   = floor((1.152e6 - 8e3)/16e3) = 71\n\nSNR_before   = 87   # dB\nSNR_after    = 80   # dB\ndecimation_r = fPDM / fs = 144\n\nP_signal                      = 1                           # normalized signal power\nP_native_noise_before         = 10^(-87/10) = 1.9953e-9     # intrinsic mic noise power\nP_total_noise_allowed         = 10^(-80/10) = 1.0000e-8     # total noise after filtering\nP_aliasing_noise_allowed      = P_total_noise_allowed - P_native_noise_before\n                              = 8.0047e-9   # max allowed aliased noise after filtering\n\n# per-band assumption: -40 dB  (per 16-kHz band above 8 kHz)\nP_aliasing_noise_before_per_band = 10^(-40/10) = 0.0001\nP_aliasing_noise_before_total    = 0.P_aliasing_noise_before_per_band * N_bands = 0.0071\n\nA_stop_lin = 0.0071 / 8.0047e-9 = 8.873e5\nA_stop_db  = 10 * log10(A_stop_lin) = 59.5               # ~60 dB stop-band attenuation required \n\nLUT Usage\nPreliminary order-of-magnitude calculations are based on this blog, but will be tweaked later: Design of a Multi-Stage PDM to PCM Decimation Pipeline\nFollowing the 144 decimation ratio, CIC can handle a maximum of 12x decimation (the bulk of decimation) with four stages and has 0.056 dB passband ripple and 125.8 dB stopband attenuation. The team will use two cascaded half-band filters: HB1 with 4x decimation and HB2 3x. Each roughly has a ~0.02 dB passband ripple and 89 dB attenuation. At the end, a generic FIR filter minimizes ripple by having a flat passband that counteracts the CIC passband droop (“compensation filter”). It also enforces stopband attenuation to a value higher than 60 dB (already achieved!), and as with the role of an FIR filter, it has 1x decimation.\n\nCIC Filter (12x in 4 stages):\n\nUses only adders and delays, no multipliers.\nAdders: 1 LUT per 4-5 adder bits, 20 adder bits * 4 stages = 20 LUTs\n\n20 adder bits comes from = Input Bit Width + Stages * log_2(CIC Decimation Ratio) = \\(1+4*log_2(12) = 16\\), adding 4 guard bits.\n\nRegisters: 52 registers (FFs) where 1 FF = 1 LUT.\n\nComes from 4 stages, each with 1 integrator and 12 combs = 52 LUTs.\n\nOverhead: 20% of preliminary cost = 15 LUTs\nTotal: Roughly 90 LUTs\n\nHalf-Band Filters:\n\nUses multipliers but FPGA can optimize and conver them to shifters/adders since half of taps are zero & nonzero coefficients are usually multiples of 2.\nHB1: 4x\n\nConverting taps to shift-adding is most efficient, but some might not always be possible. Worst case scenario, all taps will be via multiplication.\nAdders: 64 total taps –&gt; 32 nonzero coefficients, where each shift/adder is around 5 LUTs = 160 LUTs\nMultiplication: Worst case all taps are required to use multiplication: we use 4 DSP blocks (out of 8) for HB1, 28 multiplications will need to be done via LUT. 15–18 bits × 15–18 bits multiplication (15-bit PCM word size, but give or take) requires roughly 50 LUTs –&gt; 28*50=1400 LUTs\nTotal: 1400 LUTs at worst case\n\nHB2: 3x\n\nAdders: 48 total taps –&gt; 24 nonzero coefficients, where each shift/adder is around 5 LUTs = 120 LUTs\nMultiplication: Using the last 4 DSP blocks, 24-4=20 multipliers left –&gt; 20*50=1000 LUTs\nTotal: 1000 LUTs at worst case\n\n\nFIR Filter:\n\nAll error calculations are met, so FIR can be made up of precise and small number of taps. Overall, the multiplication count will be small.\nAdding: Around 16-32 taps, where 2-4 LUTs per tap = 248 LUTs\n\nLess LUTs per tap becuase of lower sample rate after decimation\n\nMultiplication: No DSP blocks, 50 LUT per multiplication –&gt; 50 * 32 = 1600 LUTs\nOverhead: 20% of preliminary cost = 300 LUTs\nTotal: 1900 LUTs\n\nOverall Total: 4400 LUTs out of iCE40UP5K’s 5280 LUTs available –&gt; 83%.\n\nA little high, but this is considering worst case; in reality, we will be implementing shift-adding as first priority (rather than multiplication).\nUsing all 8 DSP blocks provided by iCE40UP5K.\nWe can decrease LUT usage by decreasing tap counts as long as our error margins allow it.\nWe can allocate DSPs within Lattice Radiant to handle the largest or tightest coefficients instead and decrease LUT usage.\n\n\n\n\n\nFFT Parameters\nSample Rate (from FPGA’s decimation) [\\(f_S\\)]: 16 kHz –&gt; Bandwidth = 8 kHz\nFFT Size [\\(N\\)]: 1024; balanced choice from Table 4 below\nFrequency resolution per FFT bin:\n\n\\(f_S / N\\) = Sample Rate / FFT Size\nThe team is aiming for a range between 5-20 Hz/bin for musical range\n\nTime resolution (Frame duration):\n\n\\(N / f_S\\) = FFT Size / Sample Rate\n50-100 ms latency is slowest without human notification\n\n\n\n\n\n\n\n\n\n\n\n\nFFT Size\nFrequency Resolution\nTime Resolution\n\n\n\n\n512\n15.625 Hz/bin\n0.064 s = 64 ms\n\n\n1024\n7.8125 Hz/bin\n0.128 s = 128 ms\n\n\n2048\n3.90625 Hz/bin\n0.256 s = 256 ms\n\n\n\n\n\nTable 4: FFT Size Options"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "E155 Karaoke Final Project",
    "section": "",
    "text": "Quinn Miyamoto (left) is a junior engineering major at Harvey Mudd College. More specifically, she is interested in digital electronics and mechanical design. So far, she has completed courses pertaining to computer architecture, electricity and magnetism, and system-on-chip design. She has a Level Two CAD certification in Rhino, and works as a Makerspace steward for Harvey Mudd College, with a certification to teach users welding. When she is not working, you can find her reading manga/manhwa, binging bad Netflix shows, gaming, or rock-climbing.\nMayu Tatsumi (right) is a junior studying Engineering at Harvey Mudd College. She is interested in working in the camera and lighting industries and would like to become involved as an electrical engineer. She has prior experience working as a Systems Control intern specifically working on embedded systems and writing C firmware on the NXP i.MX8M processor. Outside of engineering, she is interested in movie & TV production, Formula 1, and gaming."
  },
  {
    "objectID": "index.html#about-the-team",
    "href": "index.html#about-the-team",
    "title": "E155 Karaoke Final Project",
    "section": "",
    "text": "Quinn Miyamoto (left) is a junior engineering major at Harvey Mudd College. More specifically, she is interested in digital electronics and mechanical design. So far, she has completed courses pertaining to computer architecture, electricity and magnetism, and system-on-chip design. She has a Level Two CAD certification in Rhino, and works as a Makerspace steward for Harvey Mudd College, with a certification to teach users welding. When she is not working, you can find her reading manga/manhwa, binging bad Netflix shows, gaming, or rock-climbing.\nMayu Tatsumi (right) is a junior studying Engineering at Harvey Mudd College. She is interested in working in the camera and lighting industries and would like to become involved as an electrical engineer. She has prior experience working as a Systems Control intern specifically working on embedded systems and writing C firmware on the NXP i.MX8M processor. Outside of engineering, she is interested in movie & TV production, Formula 1, and gaming."
  },
  {
    "objectID": "final_report.html",
    "href": "final_report.html",
    "title": "Final Report",
    "section": "",
    "text": "This E155 final project sought to create a karaoke machine. The design allows users to choose a song to sing, displaying lyrics and playing the song as a guide via speaker, and ultimately compares the user’s singing to the expected frequencies, displaying both a letter grade and a percent error (between received and expected frequencies) after a song finishes. The main input is a MEMS digital microphone, which goes through digital signal processing and FFT to pick up the correct frequencies at which people speak into the microphone. The LCD screen functions as the principal user interface, directing users to choose songs, displaying lyrics, and presenting grades."
  },
  {
    "objectID": "final_report.html#project-overview",
    "href": "final_report.html#project-overview",
    "title": "Final Report",
    "section": "",
    "text": "This E155 final project sought to create a karaoke machine. The design allows users to choose a song to sing, displaying lyrics and playing the song as a guide via speaker, and ultimately compares the user’s singing to the expected frequencies, displaying both a letter grade and a percent error (between received and expected frequencies) after a song finishes. The main input is a MEMS digital microphone, which goes through digital signal processing and FFT to pick up the correct frequencies at which people speak into the microphone. The LCD screen functions as the principal user interface, directing users to choose songs, displaying lyrics, and presenting grades."
  },
  {
    "objectID": "final_report.html#project-specifications",
    "href": "final_report.html#project-specifications",
    "title": "Final Report",
    "section": "Project Specifications",
    "text": "Project Specifications\n\nDesign allows the user to choose a song through external hardware\nDesign detects input frequencies between 300 to 2000 Hz\nDesign scores the user’s singing by comparing detected and expected notes\nDesign plays back the expected song through a speaker as reference\nDesign utilizes a pitch and delay media format (as seen in Lab 4)\nDisplays properly-timed lyrics on an LCD screen\nLCD display does not flicker"
  },
  {
    "objectID": "final_report.html#bill-of-materials",
    "href": "final_report.html#bill-of-materials",
    "title": "Final Report",
    "section": "Bill of Materials",
    "text": "Bill of Materials\n\n\n\nTable 1: Bill of materials\n\n\n\n\n\nPart Name\nPart Number\nQuantity\nPrice\nVendor\n\n\n\n\nAdafruit PDM MEMS Microphone Breakout\nMP34DT01-M\n1\n$11.23 ($4.95 part, $6.28 shipping + tax)\nAdafruit\n\n\nHosyond I2C 2004 LCD Module\nHD44780U\n1\n$26.32 ($16.99 part, $6.99 shipping, $2.34 estimated tax)\nAmazon\n\n\nTOTAL\n\n\n$37.55"
  },
  {
    "objectID": "final_report.html#design-details",
    "href": "final_report.html#design-details",
    "title": "Final Report",
    "section": "Design Details",
    "text": "Design Details\nThe general, high-level overview of our project — with all of the protocols used explicitly outlined — can be viewed in Figure 1 below:\n\n\n\n\n\n\nFigure 1: Design overview\n\n\n\n\nFPGA Design Overview\nOur microphone is a MP34DT01-M, a MEMS digital microphone. We drive this using a 1.536 MHz clock signal generated by the FPGA, and the microphone outputs a PDM, which is then fed into the FPGA. The top module is karaoke_top.sv, as found in fpga/src. The FPGA feeds the PDM signal through a pipeline of 3 digital audio filters: a CIC filter (cic.sv), Half-Band filter (hb.sv), and FIR filter (fir.sv).\nThese filters were used to create a decimation ratio of 96, downsampling the 1.536 MHz PDM output down to a 16 kHz output. The CIC takes the brunt of the decimation with a 24 decimation ratio in 4 stages, converts the PDM to a PCM, and normalizes the output values between -1 to 1. The Half-Band and FIR filters create a passband from 0 to 4000 Hz, with a stopband at around 8000 Hz. Both filters have a decimation ratio of 2, and their coefficients were determined using matplotlib functions.\nThe three filters generate a 16-bit, 16 kHz PCM output, with a new sample indicated by a pulse. These signals are fed into the SPI module (spi.sv), which generates a CS, SCK, and SDO, acting as the controller in this case. All relevant testbenches are found in “fpga/testbench” and the ModelSim project is found in “fpga/work” in our GitHub repository (as also mentioned below). The MCU then receives these values, acting as the peripheral, and accumulates them using the SPI peripheral, paired with the DMA peripheral.\nSome difficulties we encountered: - Finding the correct filter pipeline design and the coefficients - Minimizing resource usage - Figuring out new SPI configuration and implementing it - Synthesizing and flashing the executable\n\n\nMCU Design Overview\nAs for the MCU, one of the biggest problems was getting the LCD to consistently display the desired letters. More specifically, although the original plan was to use I2C to communicate between the two devices, it was discovered that there was a bit-expander attached to the bottom of the LCD that we had to go through first in order to actually write to our peripheral. However, because the data sheet for such a chip was so vague and therefore hard to understand, we decided to simply bypass it and send information to the data pins in parallel, instead. In total, there are eight data pins, as well as Read Select, Read/Write, and Enable pins. Thus, with the GPIO pins that were already being used for SPI, there were just barely enough pins on the breakout board (that we were actually able to use, at least) for our intended path forward.\nUnfortunately, there was still one key issue remaining: When we did this, some of the pins would display voltages of 1.5 V, as opposed to the ~3.3 V we expected. Because the characters being written on the LCD (along with the addresses being written to) are all completely dependent on the voltage levels they receive—with different high and low voltage patterns corresponding to different characters—this was obviously not good. More specifically, the minimum threshold for a voltage to be considered high by the LCD is 2.2 V, whereas the maximum threshold for a voltage to be considered low is 0.6 V; seeing as some pins had voltages floating between these two values, the LCD would randomly pick one to count it as and output the wrong thing accordingly. Ultimately, we found out that the root cause of this was the existence of two 0 ohm resistors connecting some of the MCU GPIO pins together. Thankfully, we were able to desolder these and subsequently use all of the pins as we initially intended.\n\n\nNew Non-Trivial Hardware\nNew hardware listed in section with description New hardware described with notes about the features to be implemented and how they go beyond the previous material covered in the course.\nThe two new, non-trivial pieces of hardware that are used in this project are the Hoysond LCD module and the Adafruit PDM microphone."
  },
  {
    "objectID": "final_report.html#technical-documentation",
    "href": "final_report.html#technical-documentation",
    "title": "Final Report",
    "section": "Technical Documentation",
    "text": "Technical Documentation\nThe source code for this project can be found in the associated GitHub repository.\n\nBlock Diagram\n\n\n\n\n\n\nFigure 2: Block diagram\n\n\n\nThe block diagram in Figure 2 depicts the general architecture implied by the SystemVerilog code.\n\n\nSchematic\n\n\n\n\n\n\nFigure 3: Schematic\n\n\n\nFigure 3 above depicts\nOverall, the microphone and FPGA interfacing was done in accordance with the MP34DT01-M datasheet. The most prominent feature of note is the tying of the LR port to ground, as that configures a DOUT signal pattern of valid data when the CLK signal is low and high impedance when CLK is high.\n\n\nFlowchart\n\n\n\n\n\n\nFigure 4: Flowchart\n\n\n\nThe Figure 4 flowchart provides a detailed overview of the microcontroller’s most significant routines."
  },
  {
    "objectID": "final_report.html#verification",
    "href": "final_report.html#verification",
    "title": "Final Report",
    "section": "Verification",
    "text": "Verification\nVarious means of verification were used to ensure the project’s accuracy, including the following simulation waveforms and oscilloscope traces, as well as actual experimentation with the hardware itself.\n\nTestbench Simulation\n\n\n\n\n\n\nFigure 5: CIC filter testbench\n\n\n\n\n\n\n\n\n\nFigure 6: Halfband filter testbench\n\n\n\n\n\n\n\n\n\nFigure 7: FIR filter testbench\n\n\n\n\n\n\n\n\n\nFigure 8: Top Level testbench\n\n\n\n\n\nOscilloscope Traces\n\n\n\n\n\n\nFigure 9: LCD Logic Analyzer traces"
  },
  {
    "objectID": "final_report.html#results",
    "href": "final_report.html#results",
    "title": "Final Report",
    "section": "Results",
    "text": "Results\nResults: What are the main results of your project. Results section clearly and quantitatively outlines the key performance aspects of the design with commentary to explain the design decisions.\nShort video showcasing a demonstration of the project Photos documenting final design"
  },
  {
    "objectID": "final_report.html#references",
    "href": "final_report.html#references",
    "title": "Final Report",
    "section": "References",
    "text": "References\nReferences: Citation (and hyperlinks where relevant) to any outside resources that were referenced in the design of the project. References are formatted with a clean and consistent format."
  },
  {
    "objectID": "final_report.html#acknowledgements",
    "href": "final_report.html#acknowledgements",
    "title": "Final Report",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to thank the entire MicroPs teaching team for their help in getting this project off of the ground this semester, especially Kavi Dey (’26) and Prof. Spencer. We really appreciate you!"
  },
  {
    "objectID": "midpoint_report.html",
    "href": "midpoint_report.html",
    "title": "Midpoint Report",
    "section": "",
    "text": "As of this project’s midpoint checkoff (11/20/25), the microphone is somewhat functional and sends audio samples to the FPGA board as desired. The FPGA then performs decimation on the signal by applying one CIC filter, one half-band filter, and one FIR filter, in that order. The CIC filter first decimates the 1.536 MHz PCM input by a factor of 12 through 4 stages to output a 64 kHz 16-bit PCM. The 4 initial integrator blocks accumulate the PDM stream while the decimator takes one out of 12 values. The 4 combs then compute successive differences between delayed samples, which means that they effectively undo the integrator buildup and restore a band-limited approximation of the original signal at the lower sample rate. The half-band filter is a fancy and more efficient FIR filter, using the properties of specific coefficients to halve the number of multiplications and make it more resource-efficient. The coefficients for the half-band were found by specifying a desired passband of 3950 Hz and stopband of 7900 Hz, along with a set decimation ratio of 2 (as half-bands are hardcoded to have) and number of taps, and passed all those parameters into the remez Python function. Essentially, we used this half-band filter to lower the resource strain and still decimate by 2 so we went from a 16-bit 64 kHz PCM to a 32 kHz 16-bit PCM. The FIR filter coefficients were found by calculating the passband ripple and stopband attenuation that results from the first CIC and halfband filters, and specifying the targeted values (around +- 3dB ripple and 60 dB attenuation at least). The FIR filter also had a decimation ratio of 2 to bring down the final frequency to 16 kHz (with a Nyquist of 8 kHz) that maintains all signals required ot distinguish tones during singing. All filters have a one-cycle output pulse that is asserted when there is a new valid value available. This is passed in to the SPI module, along with the final 16-bit and 16 kHz decimated PCM values, to be sent to the MCU.\nThis process of figuring out the coefficients was extremely difficult due to differences between what we had planned and what was possible. We had originally planned for a 144 decimation ratio starting from a 2.304 MHz PDM rate, with 2 halfbands (x4, x3) in between the CIC (x12) and compensation FIR filter (x1). However, we were not aware that halfbands were only as efficient as they are when they are at x2 decimation. Then, given the limited resources on the FPGA and the slowly mounting number of LUTs as we implemented the filters, we came to the decision that only a single halfband (x2) filter would be possible. Our final plan was the 12x, 4-stage CIC filter, than a single halfband (x2) filter, and the final compensation FIR filter that also decimated by 2. Every single iteration of this pipeline required re-calculating feasible coefficients for the halfbands and FIRs, which took effort and learning of a new section of the matplotlib library in Python. It also took a while implementing a pipeline on the halfband and FIR filters, along with shift-adding to reduce multiplication and, in extension, resource usage.\nAs the FPGA sends these values to the MCU over SPI, where it proceeds to first apply Z-Score normalization with the intent of maintaining amplitude measurement accuracy; it is also adjusted to account for the CIC filter gain. Note that the MCU is configured in such a way that the SPI transactions automatically send data directly to a buffer in memory via the DMA peripheral, so as to reduce the amount of processing that the core itself needs to do. Next, a Hanning window is used to reduce the signal’s spectral leakage, after which it utilizes the ARM math library functions to actually apply the FFT and take the magnitude of the resulting frequencies. From this, the dominant frequency is found and subsequently output as a note (ex. A3, B4, C5, etc.) in Segger’s Debug terminal. Additionally, while this is all occurring, a data-transfer-complete flag and an FFT-complete flag are constantly being set and reset, so that the program knows when it can start the next round of computations. (See the Flowchart section below for more specific details about the MCU’s general routine and functions.)\nFrom here on out, the team will need to get the LCD and speaker(s) working and properly interfaced with the current system, such that various songs and their lyrics can be played and displayed, respectively. There will also need to be some sort of song-selection mechanism integrated into the process. Moreover, the team has a few timing/latency concerns — regarding the delay between input audio signals and their processed outputs, in particular, as displayed in the verification waveforms below — that will need to be addressed. However, because the riskiest element of the project has already been successfully implemented, completing the rest of these tasks should not be as big of a problem."
  },
  {
    "objectID": "midpoint_report.html#current-status",
    "href": "midpoint_report.html#current-status",
    "title": "Midpoint Report",
    "section": "",
    "text": "As of this project’s midpoint checkoff (11/20/25), the microphone is somewhat functional and sends audio samples to the FPGA board as desired. The FPGA then performs decimation on the signal by applying one CIC filter, one half-band filter, and one FIR filter, in that order. The CIC filter first decimates the 1.536 MHz PCM input by a factor of 12 through 4 stages to output a 64 kHz 16-bit PCM. The 4 initial integrator blocks accumulate the PDM stream while the decimator takes one out of 12 values. The 4 combs then compute successive differences between delayed samples, which means that they effectively undo the integrator buildup and restore a band-limited approximation of the original signal at the lower sample rate. The half-band filter is a fancy and more efficient FIR filter, using the properties of specific coefficients to halve the number of multiplications and make it more resource-efficient. The coefficients for the half-band were found by specifying a desired passband of 3950 Hz and stopband of 7900 Hz, along with a set decimation ratio of 2 (as half-bands are hardcoded to have) and number of taps, and passed all those parameters into the remez Python function. Essentially, we used this half-band filter to lower the resource strain and still decimate by 2 so we went from a 16-bit 64 kHz PCM to a 32 kHz 16-bit PCM. The FIR filter coefficients were found by calculating the passband ripple and stopband attenuation that results from the first CIC and halfband filters, and specifying the targeted values (around +- 3dB ripple and 60 dB attenuation at least). The FIR filter also had a decimation ratio of 2 to bring down the final frequency to 16 kHz (with a Nyquist of 8 kHz) that maintains all signals required ot distinguish tones during singing. All filters have a one-cycle output pulse that is asserted when there is a new valid value available. This is passed in to the SPI module, along with the final 16-bit and 16 kHz decimated PCM values, to be sent to the MCU.\nThis process of figuring out the coefficients was extremely difficult due to differences between what we had planned and what was possible. We had originally planned for a 144 decimation ratio starting from a 2.304 MHz PDM rate, with 2 halfbands (x4, x3) in between the CIC (x12) and compensation FIR filter (x1). However, we were not aware that halfbands were only as efficient as they are when they are at x2 decimation. Then, given the limited resources on the FPGA and the slowly mounting number of LUTs as we implemented the filters, we came to the decision that only a single halfband (x2) filter would be possible. Our final plan was the 12x, 4-stage CIC filter, than a single halfband (x2) filter, and the final compensation FIR filter that also decimated by 2. Every single iteration of this pipeline required re-calculating feasible coefficients for the halfbands and FIRs, which took effort and learning of a new section of the matplotlib library in Python. It also took a while implementing a pipeline on the halfband and FIR filters, along with shift-adding to reduce multiplication and, in extension, resource usage.\nAs the FPGA sends these values to the MCU over SPI, where it proceeds to first apply Z-Score normalization with the intent of maintaining amplitude measurement accuracy; it is also adjusted to account for the CIC filter gain. Note that the MCU is configured in such a way that the SPI transactions automatically send data directly to a buffer in memory via the DMA peripheral, so as to reduce the amount of processing that the core itself needs to do. Next, a Hanning window is used to reduce the signal’s spectral leakage, after which it utilizes the ARM math library functions to actually apply the FFT and take the magnitude of the resulting frequencies. From this, the dominant frequency is found and subsequently output as a note (ex. A3, B4, C5, etc.) in Segger’s Debug terminal. Additionally, while this is all occurring, a data-transfer-complete flag and an FFT-complete flag are constantly being set and reset, so that the program knows when it can start the next round of computations. (See the Flowchart section below for more specific details about the MCU’s general routine and functions.)\nFrom here on out, the team will need to get the LCD and speaker(s) working and properly interfaced with the current system, such that various songs and their lyrics can be played and displayed, respectively. There will also need to be some sort of song-selection mechanism integrated into the process. Moreover, the team has a few timing/latency concerns — regarding the delay between input audio signals and their processed outputs, in particular, as displayed in the verification waveforms below — that will need to be addressed. However, because the riskiest element of the project has already been successfully implemented, completing the rest of these tasks should not be as big of a problem."
  },
  {
    "objectID": "midpoint_report.html#midpoint-specifications",
    "href": "midpoint_report.html#midpoint-specifications",
    "title": "Midpoint Report",
    "section": "Midpoint Specifications",
    "text": "Midpoint Specifications\n\nProficiency\n\nClear and concise written summary of current status\nSchematics of all breadboarded circuits\nBlock diagram of system components and the interfaces between them\nHardware demo functioning (potentially with some minor bugs)\nMore than 25% of the way to the final deliverable\nClear description of microcontroller routines\nAll external parts ordered\n\nPDM microphone\nLCD\n\n\n\n\nExcellence\n\nAll interfaces in the block diagram defined (e.g., SPI, I2C, GPIO)\nHardware demo functioning well\nWriting is well organized\nSolid grammar or spelling issues (no more than a few minor errors which do not detract from the point).\nCompleted riskiest element of the project\n\nFPGA implements all three filters to perform decimation appropriately\nMicrophone interfaces with the FPGA and MCU\n\nMore than 50% of the way to the final deliverable"
  },
  {
    "objectID": "midpoint_report.html#technical-documentation",
    "href": "midpoint_report.html#technical-documentation",
    "title": "Midpoint Report",
    "section": "Technical Documentation",
    "text": "Technical Documentation\nThe source code for this project can be found in the associated GitHub repository.\n\nBlock Diagram\n\n\n\n\n\n\nFigure 1: Block diagram\n\n\n\nThe block diagram in Figure 1 depicts the general architecture implied by the SystemVerilog code.\n\n\nSchematic\n\n\n\n\n\n\nFigure 2: Schematic\n\n\n\nFigure 2 above depicts all of the components comprising the breadboarded circuit at the time of the midpoint checkoff. This includes the PDM microphone, FPGA, and MCU; note that while the connections between the FPGA and MCU did not need to be explicitly outlined, as they are both on-board elements of the PCB that are hooked up internally, these were shown for the sake of clarity, especially regarding the SPI transactions. Overall, the microphone and FPGA interfacing was done in accordance with the MP34DT01-M datasheet. The most prominent feature of note is the tying of the LR port to ground, as that configures a DOUT signal pattern of valid data when the CLK signal is low and high impedance when CLK is high.\n\n\nFlowchart\n\n\n\n\n\n\nFigure 3: Flowchart\n\n\n\nThe Figure 3 flowchart provides a detailed overview of the microcontroller’s most significant routines.\nFirst and foremost, the main loop’s primary jobs are to 1) configure the MCU and all of its relevant peripherals, 2) continuously apply an FFT to the detected audio samples — which are, again, transmitted to the controller via SPI — in order to determine the dominant frequencies, and 3) output the corresponding note. This notably requires the help of two custom functions, frequency_determiner and note_determiner. The former makes use of the ARM math library to actually perform the FFT calculations (with some pre-processing work done to ensure greater accuracy and resolution), after which an fft_calculations_complete flag is set. Meanwhile, the latter comprises what is essentially a look-up table to output the dominant frequency as a note that is in human-readable terms. Finally, the DMA1_Channel2_IRQHandler deals with any interrupts that trigger as a result of the SPI-to-DMA-transfer-complete flag being set. More specifically, it waits until the fft_calculations_complete flag is high to copy the contents of the SPI data register (i.e. whatever audio sample the FPGA is sending over at the time) to a second buffer, named input_signal, for frequency_determiner to subsequently process; then, it resets the fft_calculations_complete so that the process may begin anew."
  },
  {
    "objectID": "midpoint_report.html#verification",
    "href": "midpoint_report.html#verification",
    "title": "Midpoint Report",
    "section": "Verification",
    "text": "Verification\nVarious means of verification were used to ensure the project’s accuracy, including the following simulation waveforms, as well as actual experimentation with the hardware itself.\n\nTestbench Simulation\n\n\n\n\n\n\nFigure 4: CIC Filter Testbench\n\n\n\n\n\n\n\n\n\nFigure 5: Halfband Filter Testbench\n\n\n\n\n\n\n\n\n\nFigure 6: FIR Filter Testbench\n\n\n\n\n\n\n\n\n\nFigure 7: Top Level Testbench"
  }
]