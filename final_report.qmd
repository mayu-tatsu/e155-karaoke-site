---
title: "Final Report"

tbl-cap-location: bottom
---

## Project Overview
This E155 final project sought to create a karaoke machine. 
The design allows users to choose a song to sing, displaying lyrics and playing the song as a guide via speaker, and ultimately compares the user’s singing to the expected frequencies, displaying both a letter grade and a percent error (between received and expected frequencies) after a song finishes.
The main input is a MEMS digital microphone, which goes through digital signal processing and FFT to pick up the correct frequencies at which people speak into the microphone.
The LCD screen functions as the principal user interface, directing users to choose songs, displaying lyrics, and presenting grades. 


## Project Specifications
* Design allows the user to choose a song through external hardware
* Design detects input frequencies between 300 to 2000 Hz
* Design scores the user’s singing by comparing detected and expected notes
* Design plays back the expected song through a speaker as reference
* Design utilizes a pitch and delay media format (as seen in Lab 4)
* Displays properly-timed lyrics on an LCD screen
* LCD display does not flicker


## Bill of Materials
| **Part Name**                         | **Part Number**                                                                                   | **Quantity** | **Price**                                                   | **Vendor**                                                  |
|:-------------------------------------:|:-------------------------------------------------------------------------------------------------:|:------------:|:-----------------------------------------------------------:|:-----------------------------------------------------------:|
| Adafruit PDM MEMS Microphone Breakout | [MP34DT01-M](https://www.st.com/en/audio-ics/mp34dt01-m.html)                                     | 1            | $11.23 *($4.95 part, $6.28 shipping + tax)*                 | [Adafruit](https://www.adafruit.com/product/3492)           |
| Hosyond I2C 2004 LCD Module           | [HD44780U](https://dfimg.dfrobot.com/enshop/image/data/DFR0154/LCD2004%20hd44780%20Datasheet.pdf) | 1            | $26.32 *($16.99 part, $6.99 shipping, $2.34 estimated tax)* | [Amazon](https://www.amazon.com/gp/product/B0C1G9GBRZ?th=1) |
| **TOTAL**                             |                                                                                                   |              | $37.55                                                      |                                                             |
: Bill of materials {#tbl-bom}


## Design Details
The general, high-level overview of our project — with all of the protocols used explicitly outlined — can be viewed in [Figure 1](#fpga-design-overview) below:

![Design overview](images/final_overview_diagram.jpg){#fig-final-overview-diagram}

### New Non-Trivial Hardware
The two new, non-trivial pieces of hardware that are used in this project are the Adafruit PDM microphone and the Hoysond LCD module.

#### Adafruit PDM Microphone
We used a MP34DT01-M, a MEMS digital microphone.
It outputs data in Pulse-Density Modulation (PDM) format, which is a format of representing an analog signal in a single bit, with the density of 1’s and 0’s reflecting the amplitude of the signal.

This microphone itself took 4 inputs: a 3.3V power supply, a ground, a L/R channel selector for simplified stereo applications, and a synchronization input clock.
The input clock was valid between frequencies of 3.25 to 1 MHz, which meant we were able to select a frequency and drive it from the FPGA. We chose to ground L/R out of default.
The output was the Dout pin, and could be read by an FPGA pin in PDM format. The clock and Dout were connected directly to the FPGA board to minimize lag and voltage drop.

Within E155, there has been no usage of this PDM format.
The closest data format or acquisition method we had gone over was quadrature encoders, which we used in Lab 5.
They were able to represent analog motion in two 1-bit digital signals, but PDM is a distinct method of representing analog waves in a single bit, which is beyond the previous material of this course.

#### Hoysond LCD Module
The LCD used seems to comprise the HD44780 Hitachi controller chip, as well as a PCF8574A bit-expander for I2C interfacing.
The screen itself has four rows and 20 columns — or, in other words, 80 total spaces — with which to write characters of its user's choosing.
It needs 5 V of power to display characters properly, with the ability to adjust both its backlight brightness and contrast.
There are two options for sending it instructions: either over I2C or directly through its 11-pin parallel interface, including:

* 1 Enable bit (E)
* 1 Register Select bit (RS)
* 1 Read/Write bit (RW)
* 8 data pins (D0 - D7)

More specifics about these pins and their respective functionalities can be found in the [datasheet](https://www.handsontec.com/dataspecs/I2C_2004_LCD.pdf) for the LCD's Hitachi controller, specifically.
Regardless, for both methods of communication, the module uses the sequences of high and low voltages detected in tandem with a look-up table, with each operation having its own lead-in op-code (such as the Set Address and Clear Display functions) and each character having its own unique sequence associated with it.
The latter can be viewed rather clearly in [Figure 2](#fig-lcd-look-up-table), as follows:

![LCD character options](images/lcd_look_up_table.png){#fig-lcd-look-up-table width=60%}

Note that if you decide to communicate with the LCD by sending bits to all of its pins in parallel, each transaction will have to be ended with a short pulse of the Enable (E) bit, so as to tell the module that its information has been completely updated.

Moreover, the LCD requires a specifically-timed initialization sequence in order to fully function.
This is outlined in [Figure 3](#fig-lcd-initialization).

![LCD initialization](images/lcd_initialization_sequence.png){#fig-lcd-initialization width=60%}

Ultimately, the features implemented with this hardware go above and beyond the previous material covered in class, as they require the configuration of an external display.
More specifically, we had to learn about the different communication protocols that an LCD can use, and compare the pros and cons of both.
Eventually, we came to the conclusion that using a parallel interface would be best because 1) when there are pins to spare for it, it's the fastest, and 2) the [datasheet](https://www.nxp.com/docs/en/data-sheet/PCF8574_PCF8574A.pdf) for the PCF8574A bit-expander is vague and thus, it is extremely hard to parse how to interact with it when using I2C; in the interest of not getting hung-up over something that could be easily avoided, we decided to bypass it entirely.
(See the [Schematic section](#sec-schematic) below for more details on some bugs that we needed to address when doing this.)

### FPGA Design Overview
The FPGA is in control of the microphone, processing its data, and sending that data to the MCU. Our microphone is a MP34DT01-M, a MEMS digital microphone.
We drive this using a 1.536 MHz clock signal generated by the FPGA, and the microphone outputs data in Pulse-Density Modulation (PDM) format, which is then fed back into the FPGA.
PDM is a format of representing an analog signal in a single bit, with the density of 1’s and 0’s reflecting the amplitude of the [Figure 4](#fig-pdm-vs-analog-signal) signal.

![PDM vs. Analog signals](images/pdm_vs_analog_signal.png){#fig-pdm-vs-analog-signal width=60%}

The top module is karaoke_top.sv, as found in the [GitHub](https://github.com/mayu-tatsu/e155-karaoke)'s fpga/src.
The FPGA feeds the PDM signal through a pipeline of 3 digital audio filters: a CIC filter / cic.sv, half-band filter / hb.sv, and FIR filter / fir.sv.

These three filters were used to create a decimation ratio of 96, downsampling the 1.536 MHz PDM output down to a 16 kHz output.
The CIC takes the brunt of the decimation with a 24 decimation ratio in 4 stages, converts the PDM to a PCM, and normalizes the output values between -1 to 1.
The half-band and FIR filters create a passband from 0 to 4000 Hz, with a stopband at around 8000 Hz.
Both filters have a decimation ratio of 2, and their coefficients were determined using matplotlib functions.

The three filters generate a 16-bit, 16 kHz PCM output, with a new sample indicated by a pulse.
These signals are fed into the SPI module / spi.sv, which generates a CS, SCK, and SDO, acting as the controller/master in this case.
All relevant testbenches are found in fpga/testbench and the ModelSim project is found in fpga/work.
The MCU then receives these values, acting as the peripheral/slave, and accumulates them using the SPI peripheral, paired with the DMA peripheral.

Some difficulties we encountered:

* Finding the correct filter pipeline design and the coefficients for the half-band and FIR
* Minimizing resource usage
* Figuring out new SPI configuration and implementing it
* Synthesizing and flashing the executable

Initially, we were naively hoping to create a decimation ratio of 144, bringing a PDM input rate of 2.304 MHz down to 16 kHz.
This was due to a misunderstanding of half-band filters and the resources we could fit onto the board.
Half-band filters are optimized FIR filters that require only half the number of taps, and therefore multiplications, but also can only decimate (or interpolate) at a rate of 2 every filter.
We had assumed that half-bands filters would be able to handle 3x and 4x decimation (which, no, is not possible) during the project proposal stage. 
Once we read up more on half-bands, we decided to move to a 1.536 MHz to decimate it down to 16 kHz using a decimation ratio of 96.
We determined that, for our purposes, the CIC filter would be able to handle a 24 decimation ratio without much change in ripple or attenuation via this [Figure 5]() chart:

![CIC decimation chart](images/decimation_chart.png){#fig-decimation-chart width=80%}

Since we wanted to make sure that the FIR would be able to handle everything in 16 taps to keep resource levels low, we decided to use two half-bands and keep the FIR only to minimize passband ripple and maximize stopband attenuation.
However, when we loaded this onto the FPGA, there were not enough LUTs to accommodate this design.
As a result, we settled on a finalized design of a 24-decimation ratio, 4-stage CIC filter, a half-band filter, and a 2x decimating and correcting final FIR filter.

When it came to determining the coefficients, we started off trying to use some MATLAB code, but switched to Python with its easier remez() function.
The code for this can be found here. When it came to implementing these filters in Verilog, we mentioned that it was difficult due to resource constraints.
There was some trial-and-error involved, trying to get it down from 170+% resource usage down to our final 94% LUT4 usage.
Our biggest issue was the multiplications required. The FPGA only has 8 DSP blocks, and all of those were devoted to the half-band multiplications.
Which meant that the CIC, FIR, and the rest of the half-band additions all had to fit their calculations in the LUTs.
The CIC was generally resource-optimized already due to its perk requiring only adders and delays by design.
The FIR and half-band took some tweaking.
We implemented pipelining in both filters to keep the critical path short and allow the synthesis tool to map arithmetic into smaller, slower LUT-based adders rather than huge blocks dedicated to multiplication.
Then, we replaced all true multipliers in the FIR with hardcoded shift-add coefficient implementations, which finally pushed down our LUT usage below 100%. 

We also hit some snags while implementing the SPI.
We were using some code based on Lab 7, which assumes a MCU-master, FPGA-slave configuration.
However, it quickly came to be that our FPGA should be the master in our context, and as we switched those things around, as a result, we needed a new chip select (CS) signal, and switched around some pins.
However, there was some confusion about which board should generate the CS signal between us partners, and the silkscreen and boards were generally designed around the assumption that the MCU would always be the master.
That, and some two sets of pins coming out of the FPGA both labelled SCK/CS/MISO-CIPO took a day or two to figure out.

Finally, once we got almost everything working regarding the MCU peripherals and the FPGA SPI module, we had some issues where, even in ambient noise, the microphone, filters, and FFTs combined would produce outputs ranging from 100 to 6000 Hz, jumping values multiple times in a second.
We knew from verification and testing that all of these mechanisms should work in isolation, so we weren’t sure where the mix-up was coming from.
In a last-ditch test to see if the ambient noise was too much (which it wasn’t), we left the lab to go to a quieter room.
It turns out that synthesizing and loading the executable from Quinn’s personal computer through OpenFPGALoader fixed completely all of our issues despite using the same exact code and project setup (same .rdf files for Lattice, same Lattice version).
There may be some timing constraints that we never specified that could be causing these mapping inconsistencies, but overall, we are still unsure exactly why this is.
However, as a result, the microphone and FFT are now able to accurately detect and output frequencies. 

### MCU Design Overview
In short, our MCU serves as the primary driver for everything in this project that isn't our microphone.
The most significant components of its design — comprising both peripheral configurations and general functionalities — are listed and expounded upon as follows:

#### SPI
First and foremost, SPI Receive-Only mode is set up such that the FPGA acts as the controller in every transaction, while the MCU acts exclusively as the peripheral.
Although we initially used the SPI initialization function provided in [Lab 7](https://qmiyamoto.github.io/E155-Portfolio/labs/lab7/lab7.html) as starter code, we quickly realized that this wouldn't work, due to the nature of what we were trying to accomplish: a one-sided intake of information that the FPGA initiates, as opposed to two-way communication started off by the MCU.
Taking advantage of the built-in connections between the FPGA and MCU pins on our PCB, we eventually set up the latter to continuously receive SCK, CS, and SDO signals as input from the former.
It then stores the SDO data — our raw audio samples — in its data register, which we configure to be accessible by DMA.

#### DMA
The DMA peripheral, in essence, negates the need to use the spiSendReceive() function every time we want to read the data our MCU is receiving.


#### Audio


#### Timing


#### FFT


#### Grading


#### LCD



## Technical Documentation
The source code for this project can be found in the associated [GitHub repository](https://github.com/mayu-tatsu/e155-karaoke).

### Block Diagram
![Block diagram](images/final_block_diagram.png){#fig-final-block-diagram}

The block diagram in [Figure 4](#fig-final-block-diagram) depicts the general architecture implied by the SystemVerilog code.

[TO-DO!]

### Schematic {#sec-schematic}
![Schematic](images/final_schematic.png){#fig-final-schematic}

[Figure 5](#fig-final-schematic) above depicts 

[TO-DO!]

Overall, the microphone and FPGA interfacing was done in accordance with the [MP34DT01-M datasheet](https://github.com/mayu-tatsu/e155-karaoke-site/blob/main/files/mp34dt01-m.pdf).
The most prominent feature of note is the tying of the LR port to ground, as that configures a DOUT signal pattern of valid data when the CLK signal is low and high impedance when CLK is high.

### Flowchart {#sec-flowchart}
[TO-DO!]

![Flowchart](images/final_flowchart.png){#fig-final-flowchart}

The [Figure 6](#fig-final-flowchart) flowchart provides a detailed overview of the microcontroller's most significant routines.


## Verification
Various means of verification were used to ensure the project's accuracy, including the following simulation waveforms and oscilloscope traces, as well as actual experimentation with the hardware itself.

### Testbench Simulation {#sec-testbench-simulation}
![CIC filter testbench](images/midpoint_cic_tb_waves.png){#fig-cic-tb}

[TO-DO!]

![Halfband filter testbench](images/midpoint_hb_tb_waves.png){#fig-hb-tb}

[TO-DO!]

![FIR filter testbench](images/midpoint_fir_tb_waves.png){#fig-fir-tb}

[TO-DO!]

![Top Level testbench](images/midpoint_top_tb_waves.png){#fig-top-tb}

[TO-DO!]

### Oscilloscope Traces
![LCD Logic Analyzer traces](images/lcd_logic_analyzer.png){#fig-lcd-logic-analyzer}

[TO-DO!]


## Results
[TO-DO!]

Results: What are the main results of your project.
Results section clearly and quantitatively outlines the key performance aspects of the design with commentary to explain the design decisions.

::: {#fig-video}
{{< video https://youtu.be/vw2rmU5o_nw?si=B0km_b63cXBgvwma >}}

Demo video
:::

![Final build](images/final_build.jpg){#fig-final-build}

![Team on Demo Day](images/demo_day_team.jpg){#fig-demo-day-team}


## References
[E155](https://hmc-e155.github.io/): Course website.

[STM32L432KC Datasheet](https://hmc-e155.github.io/assets/doc/ds11451-stm32l432kc.pdf): STM32 MCU datasheet.

[STM32L432KC Reference Manual](https://hmc-e155.github.io/assets/doc/rm0394-stm32l41xxx42xxx43xxx44xxx45xxx46xxx-advanced-armbased-32bit-mcus-stmicroelectronics.pdf): STM32 MCU reference manual.

[Quinn Miyamoto's E155 Portfolio](https://qmiyamoto.github.io/E155-Portfolio/): Team member Quinn Miyamoto's portfolio of this course's labs.

[Fix That Note! E155 Final Project Portfolio](https://jacksonphilion.github.io/final-project-portfolio/): Past E155 portfolio for the Fix That Note! project, which involved telling a user what note their system was detecting.

[An Intuitive Look at Moving Average and CIC Filters](https://tomverbeure.github.io/2020/09/30/Moving-Average-and-CIC-Filters.html): A series of blogs made by Tom Verbeure on designing a pipeline for audio decimation and filtering.

[FIR Halfband Filter Design](https://www.mathworks.com/help/dsp/ug/fir-halfband-filter-design.html): A MATLAB guide to designing half-band filters, used in conjunction with the DSP-Related article below.

[Simplest Calculation of Half-band Filter Coefficients](https://www.dsprelated.com/showarticle/1113.php): An online guide to designing half-band filter coefficients.

[jaycordaro/half-band-filter](https://github.com/jaycordaro/half-band-filter): An implementation of a half-band FIR filter, from MATLAB to fixed point in SystemVerilog.

[MEMS audio sensor omnidirectional digital microphone](https://cdn-learn.adafruit.com/assets/assets/000/049/977/original/MP34DT01-M.pdf): Datasheet for MP34DT01-M.

[Interface 16×2 LCD with STM32 (No I2C) — 4-bit Guide](https://controllerstech.com/interface-lcd-16x2-with-stm32-without-i2c/): A guide to interfacing an LCD with an STM32 MCU with an 11-line parallel bus, instead of I2C.

[STM32 LCD 16×2 Library & Example | LCD Display Interfacing](https://deepbluembedded.com/stm32-lcd-16x2-tutorial-library-alphanumeric-lcd-16x2-interfacing/): A guide to initializing and writing to an LCD using an STM32 MCU.

[I2C Serial Interface 20x4 LCD Module](https://www.handsontec.com/dataspecs/I2C_2004_LCD.pdf): Datasheet for the LCD's HD44780 controller chip.

[MC21605A6W-FPTLW](https://mm.digikey.com/Volume0/opasdata/d220001/medias/docus/3477/MC21605A6W-FPTLW.pdf): Alternative LCD datasheet.

[Generating signals with STM32L4 timer, DMA and DAC](https://m0agx.eu/generating-signals-with-stm32l4-timer-dma-and-dac.html): A guide to interfacing DMA with SPI.

[Fast Fourier Transform using the ARM CMSIS Library within the STM32 MCUs](https://youtu.be/Z3_YsXXgWzw?si=PaWCxyRoxPfmdG3T): A video tutorial on how to pick a dominant frequency out of a given signal on the STM32 MCU, using ARM math functions (including the FFT).

[Normalizing Signals for Enhanced Analysis and Interpretation](https://thetechylife.com/how-do-you-normalize-a-signal/): A guide to normalizing signals as preparation for Fourier Transforms.

[STMicroelectronics/cmsis-core](https://github.com/STMicroelectronics/cmsis-core/tree/10c319e2ed1a53a382f43a99eaa2b7b03d5b3489/DSP/Source): GitHub repository of all ARM math functions.


## Acknowledgements
We would like to thank the entire MicroPs teaching team for their help in getting this project off of the ground this semester, especially [Kavi Dey](https://www.linkedin.com/in/kavidey/) ('26) and Prof. Spencer.
Additionally, special thanks goes out to [Cole Plepel](https://www.linkedin.com/in/cole-plepel/) ('27) for transcribing our karaoke machine's music.
We really appreciate you!